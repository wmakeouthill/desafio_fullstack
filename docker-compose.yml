version: "3.8"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: email-classifier-api
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - AI_PROVIDER=${AI_PROVIDER:-openai}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_MODELS_FALLBACK=${OPENAI_MODELS_FALLBACK:-gpt-3.5-turbo}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-4000}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-2.5-flash}
      - GEMINI_MODELS_FALLBACK=${GEMINI_MODELS_FALLBACK:-gemini-2.0-flash,gemini-2.0-flash-lite}
      - GEMINI_MAX_TOKENS=${GEMINI_MAX_TOKENS:-8192}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:4200,http://localhost:3000}
      - DEBUG=${DEBUG:-false}
    env_file:
      - .env
    restart: unless-stopped
    networks:
      - email-classifier-network
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/v1/emails/health')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Frontend (opcional - pode usar ng serve em desenvolvimento)
  # frontend:
  #   build:
  #     context: ./frontend
  #     dockerfile: Dockerfile
  #   container_name: email-classifier-frontend
  #   ports:
  #     - "4200:80"
  #   depends_on:
  #     - backend
  #   networks:
  #     - email-classifier-network

networks:
  email-classifier-network:
    driver: bridge
